- Acquired proficiency in web scraping using Python libraries like BeautifulSoup and requests and learned how to extract data from HTML web pages efficiently.
- Implemented error-handling strategies(handling HTTP errors, e.g. 403 forbidden) to ensure the scraping process runs smoothly and handles any website-related issues.
- Handled the HTTP error (403 forbidden error) by setting a custom User-Agent header in the request sent to the website. This header makes the request appear as if it's coming from a regular browser rather than a scraper, reducing the likelihood of being blocked by the website. By including this header in my request, I am less likely to encounter HTTP errors related to forbidden access or being recognized as a scraper. This approach is a common strategy to handle HTTP errors in web scraping projects.
